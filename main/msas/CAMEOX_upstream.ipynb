{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare CAMEOX inputs for a entanglement pair\n",
    "\n",
    "**Version**: 0.8 (Mar 2022)\n",
    "\n",
    "**Abstract**: Upstream CAMEOX pipeline \n",
    "\n",
    "**Changes**: Improved and extended after installing hh-suite; tackles problem with missing initial Met; includes initial tests and call to jackhmmer.\n",
    "\n",
    "**Environment**: CZ jupyterhub on Mammoth. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path, PosixPath\n",
    "import pwd\n",
    "import sys\n",
    "import time\n",
    "from typing import Set, List, Union, Any, Dict, Tuple, Iterable, NewType, Optional, NamedTuple, Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (sys.version_info.major == 3 and sys.version_info.minor >= 8):\n",
    "  print('ERROR! This script requires Python 3.8 or higher.')\n",
    "  print(f'You are using Python {sys.version_info.major}.{sys.version_info.minor}')\n",
    "  sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from evcouplings.align.alignment import Alignment\n",
    "from evcouplings.align.protocol import modify_alignment, cut_sequence\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check version of several libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 1.3.4\n",
      "NumPy version: 1.21.4\n",
      "SciPy version: 1.7.1\n",
      "Matplotlib version: 3.2.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Pandas version: {(pdver := pd.__version__)}')\n",
    "if not ((pdvers := list(map(int, pdver.split('.'))))[0] >=1 and pdvers[1] >=1):\n",
    "  print('\\tERROR! This script requires pandas 1.1.0 or higher.')\n",
    "  print(f'\\tYou are using pandas {pdver}')\n",
    "  sys.exit(2)\n",
    "print(f'NumPy version: {np.__version__}')\n",
    "print(f'SciPy version: {scipy.__version__}')\n",
    "print(f'Matplotlib version: {mpl.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = NewType('Id', int)\n",
    "Seq = NewType('Seq', str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME: Final[str] = pwd.getpwuid(os.getuid()).pw_name\n",
    "GPUSERVER: Final[str] = 'pascal'  # Update this with your GPU machine at LC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug: bool = False\n",
    "verbose: bool = True\n",
    "interactive: bool = True  # Disable in case of trouble storing the notebook with plotly rendered i-plots\n",
    "          \n",
    "def vprint(*arguments, **kargs) -> None:\n",
    "    \"\"\"Print only if verbose mode is enabled\"\"\"\n",
    "    if verbose:\n",
    "        print(*arguments, **kargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proteins: List[str] = ['infA_ecoli_GREMLIN',\n",
    "#                       'prmC_pf5_uref100',\n",
    "#                       'aroB_pf5_uref100',\n",
    "#                       'infA_ecoli_uref100',\n",
    "#                       'cysJ_pf5_uref100',\n",
    "#                       'aroB_ecoli_uref100',\n",
    "#                       'cysJ_ecoli_uref100',\n",
    "#                       'aroB_ecoli_GREMLIN',\n",
    "#                       'infA_pf5_uref100']\n",
    "proteins: List[str] = ['cymR_pputida_uref100'] # Dante's\n",
    "#proteins: List[str] = ['infA_pf5_ortho', 'aroB_pf5_ortho',\n",
    "#                       'infA_pf5_ortho_bis', 'aroB_pf5_ortho_bis',\n",
    "#                       'infA_pf5_ortho_tris', 'aroB_pf5_ortho_tris',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial tasks and jackhmmer\n",
    "Tips:\n",
    "* Place the CAMEOX repo in your home directory under 'cameos' directory or,\n",
    "* Create a symlink in your home directory pointing to the group 'cameos' directory\n",
    "* Set that location in the BASE constant below (if different from the options shown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databases\n",
    "UNIREF100: Final[PosixPath] = Path('/usr/workspace/kpath/cameos/dbs/uniref100.fasta')\n",
    "UNIREF90: Final[PosixPath] = Path('/usr/workspace/kpath/cameos/dbs/uniref90.fasta')\n",
    "# CAMEOS/X\n",
    "BASE: Final[PosixPath] = Path('/usr/workspace/kpath/cameos/')\n",
    "#BASE: Final[PosixPath] = Path.home() / Path('cameos') \n",
    "MSAS_BASE: Final[PosixPath] = BASE / Path('CAMEOX/main/msas/')\n",
    "# Jackhmmer\n",
    "JCKHMM_SH: Final[PosixPath] = Path('jackhmmer.sh')\n",
    "JCKHMM_BIN: Final[PosixPath] = Path('/usr/workspace/kpath/cameos/hmmer/bin')\n",
    "JCKHMM_BTHRE: Final[float] = 0.5  # Jackhmmer bitscore threshold\n",
    "JCKHMM_NITER: Final[int] = 5 # Jackhmmer num of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test basic prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Check input requirements for cymR_pputida_uref100: OK!\n",
      "> Further checks... OK!\n"
     ]
    }
   ],
   "source": [
    "failure: bool = False\n",
    "for protein in proteins:\n",
    "    print(f'> Check input requirements for {protein}: ', end='')\n",
    "    base_path = Path(protein)\n",
    "    wt_path = Path(protein, 'wt.fa')\n",
    "    if not base_path.is_dir():\n",
    "        print('Missing dir!')\n",
    "        failure = True\n",
    "    elif not wt_path.is_file():\n",
    "        print('Missing WT fasta file!')        \n",
    "        failure = True\n",
    "    else:\n",
    "        print('OK!')\n",
    "print('> Further checks... ', end='')\n",
    "if not UNIREF100.is_file() or not UNIREF90.is_file():\n",
    "    print('UniProt databases are missing!')\n",
    "    failure = True    \n",
    "if not JCKHMM_SH.is_file():\n",
    "    print('Unable to find jackhmmer.sh!')\n",
    "    failure = True\n",
    "if not JCKHMM_BIN.is_dir():\n",
    "    print('Jackhmmer bin dir is missing!')\n",
    "    failure = True    \n",
    "if not BASE.is_dir():\n",
    "    print('CAMEOS base dir is missing!')\n",
    "    failure = True    \n",
    "if not MSAS_BASE.is_dir():\n",
    "    print('CAMEOX msas subdir is missing!')\n",
    "    failure = True    \n",
    "if failure:\n",
    "    raise FileNotFoundError('There are missing files/dirs needed for the pipeline')\n",
    "else:\n",
    "    print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit jackhmmer job to batch system in current machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Submitting jackhmmer job for cymR_pputida_uref100...\n",
      "['Submitted batch job 91561']\n"
     ]
    }
   ],
   "source": [
    "for protein in proteins:\n",
    "    print(f'> Submitting jackhmmer job for {protein}...')    \n",
    "    # USAGE: sbatch jackhmmer.sh <bin_dir> <prot_dir> <bitscore_threshold> <niter> <seqdb>\n",
    "    sbatch_msg = !sbatch {JCKHMM_SH} {JCKHMM_BIN} {MSAS_BASE/Path(protein)} {JCKHMM_BTHRE} {JCKHMM_NITER} {UNIREF100}\n",
    "    print(sbatch_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "             90256    pbatch jackhmme  metagen  R       0:10      1 mammoth63\n",
      "...............................................................................................................................................................................................................................\n",
      "              JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) \n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# Check the jobs are finished before proceeding further\n",
    "squeue_msg = !squeue -u {USERNAME}\n",
    "done:bool = False\n",
    "print('\\n'.join(squeue_msg))\n",
    "while not done:\n",
    "    if any('jackhmme' in line for line in squeue_msg): \n",
    "        print('.', end='', flush=True)\n",
    "        time.sleep(20)\n",
    "        squeue_msg = !squeue -u {USERNAME}\n",
    "    else:\n",
    "        done = True\n",
    "        print('\\n', '\\n'.join(squeue_msg), '\\nDONE!')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocess MSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "HHFILTER: Final[PosixPath] = BASE / Path('hhsuite/bin/hhfilter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postMSA(prefix:PosixPath, fmt:str='stockholm', met_start=True):\n",
    "    \"\"\"Postprocess (filter) HMMER alignments\"\"\"\n",
    "\n",
    "    target_fname: PosixPath = Path(prefix, 'wt.fa')\n",
    "    msa_ext: str\n",
    "    if fmt == 'stockholm':\n",
    "        msa_ext = '.sto'\n",
    "    elif fmt == 'fasta':\n",
    "        msa_ext = '.fa'\n",
    "    elif fmt == 'a3m':\n",
    "        msa_ext = '.a3m'\n",
    "    else:\n",
    "        raise ValueError(f'Unknown format \"{fmt}\"!')\n",
    "        \n",
    "    msa_fname: PosixPath = Path(prefix, 'alignment').with_suffix(msa_ext)\n",
    "    output_prefix: PosixPath = Path(prefix, prefix)\n",
    "        \n",
    "    # Load target/wt sequence from fasta file (typically wt.fa)\n",
    "    tgseq = SeqIO.read(target_fname, format='fasta')\n",
    "    \n",
    "    # Get raw alignment from stockholm file\n",
    "    with open(msa_fname) as fsto:\n",
    "        ali_raw = Alignment.from_file(fsto, fmt)\n",
    "    if met_start and tgseq.seq[0] == 'M': # Force M always in the 1st column if present in the WT    \n",
    "        ali_raw = ali_raw.replace('-', 'M', columns=[0])\n",
    "    print(f'INFO: Input MSA has {ali_raw.N} sequences and {ali_raw.L} columns')\n",
    "\n",
    "    # center alignment around focus/search sequence\n",
    "    focus_cols = np.array([c != \"-\" for c in ali_raw[0]])\n",
    "    focus_ali = ali_raw.select(columns=focus_cols)\n",
    "   \n",
    "    if fmt == 'stockholm':\n",
    "        assert len(tgseq.seq) == len(focus_ali[0]), (\n",
    "            f'{len(focus_cols)} focus cols, expected {len(tgseq.seq)}')\n",
    "    else:\n",
    "        if len(tgseq.seq) != len(focus_ali[0]):\n",
    "            print(f'WARNING! {len(focus_cols)} focus cols, expected {len(tgseq.seq)}')\n",
    "\n",
    "    TARGET_SEQ_INDEX = 0\n",
    "    REGION_START = 0\n",
    "    kwargs = {\n",
    "            'prefix': str(output_prefix),\n",
    "            'seqid_filter': None,  \n",
    "            # 'seqid_filter' corresponds to \"threshold\" in run_hhfilter (default: 95): Sequence identity\n",
    "            #  threshold for maximum pairwise identity (between 0 and 100)\n",
    "            'hhfilter': str(HHFILTER), \n",
    "            # 'hhfilter' corresponds to \"binary\" in run_hhfilter: Path to hhfilter binary\n",
    "            'minimum_sequence_coverage': 50,  # Use integer in [0, 100] or real in [0.0, 1.0] (Chloe: 50; test: 98)\n",
    "            'minimum_column_coverage': 50,  # Use integer in [0, 100] or real in [0.0, 1.0] (Chloe: 70; test: 0)\n",
    "            # 'minimum_column_coverage' makes columns with too many gaps lowercase; 0 covers all columns.\n",
    "            'compute_num_effective_seqs': False,\n",
    "            'theta': 0.8,  # value of theta in computing sequence weights\n",
    "    }\n",
    "    mod_outcfg, ali = modify_alignment(\n",
    "        focus_ali, TARGET_SEQ_INDEX, tgseq.id, REGION_START, **kwargs)\n",
    "    print(f'INFO: Output MSA has {ali.N} sequences and {ali.L} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_msa(protein: str, srcfmt='a3m', tgtfmt='fasta') -> None:\n",
    "    \"\"\"Convert MSA format from source to target\"\"\"\n",
    "    \n",
    "    src_path = Path(protein, protein).with_suffix('.' + srcfmt)\n",
    "    tgt_path = Path(protein, protein).with_suffix('.' + tgtfmt)\n",
    "\n",
    "    with open(src_path) as src, open(tgt_path, 'w') as tgt:\n",
    "        alig = Alignment.from_file(src, srcfmt)\n",
    "        vprint(f'INFO: Input MSA has {alig.N} sequences and {alig.L} columns')\n",
    "        alig.write(tgt, format=tgtfmt, width=sys.maxsize)  # No width limit (for fasta)\n",
    "        print(f'Convert {src_path} --> {tgt_path} OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Postprocessing alignment for infA_pf5_ortho...\n",
      "INFO: Input MSA has 653 sequences and 72 columns\n",
      "INFO: Output MSA has 653 sequences and 72 columns\n",
      "\tDone with alignment in a3m format for infA_pf5_ortho!\n",
      "> Postprocessing alignment for aroB_pf5_ortho...\n",
      "INFO: Input MSA has 620 sequences and 366 columns\n",
      "INFO: Output MSA has 620 sequences and 366 columns\n",
      "\tDone with alignment in a3m format for aroB_pf5_ortho!\n",
      "> Postprocessing alignment for infA_pf5_ortho_bis...\n",
      "INFO: Input MSA has 3087 sequences and 72 columns\n",
      "INFO: Output MSA has 3087 sequences and 72 columns\n",
      "\tDone with alignment in a3m format for infA_pf5_ortho_bis!\n",
      "> Postprocessing alignment for aroB_pf5_ortho_bis...\n",
      "INFO: Input MSA has 5492 sequences and 366 columns\n",
      "INFO: Output MSA has 5492 sequences and 366 columns\n",
      "\tDone with alignment in a3m format for aroB_pf5_ortho_bis!\n",
      "> Postprocessing alignment for infA_pf5_ortho_tris...\n",
      "INFO: Input MSA has 5850 sequences and 98 columns\n",
      "INFO: Output MSA has 5850 sequences and 72 columns\n",
      "\tDone with alignment in fasta format for infA_pf5_ortho_tris!\n",
      "> Postprocessing alignment for aroB_pf5_ortho_tris...\n",
      "INFO: Input MSA has 5564 sequences and 931 columns\n",
      "INFO: Output MSA has 5554 sequences and 366 columns\n",
      "\tDone with alignment in fasta format for aroB_pf5_ortho_tris!\n",
      "CPU times: user 6.89 s, sys: 76.3 ms, total: 6.97 s\n",
      "Wall time: 7.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for protein in proteins:\n",
    "    print(f'> Postprocessing alignment for {protein}...')\n",
    "    for fmt in ['stockholm', 'fasta', 'a3m']:\n",
    "        try:\n",
    "            postMSA(protein, fmt=fmt)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        else:\n",
    "            print(f'\\tDone with alignment in {fmt} format for {protein}!')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get MSAs in fasta format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‘infA_pf5_ortho/infA_pf5_ortho.a2m’ -> ‘infA_pf5_ortho/infA_pf5_ortho.a3m’\n",
      "‘aroB_pf5_ortho/aroB_pf5_ortho.a2m’ -> ‘aroB_pf5_ortho/aroB_pf5_ortho.a3m’\n",
      "‘infA_pf5_ortho_bis/infA_pf5_ortho_bis.a2m’ -> ‘infA_pf5_ortho_bis/infA_pf5_ortho_bis.a3m’\n",
      "‘aroB_pf5_ortho_bis/aroB_pf5_ortho_bis.a2m’ -> ‘aroB_pf5_ortho_bis/aroB_pf5_ortho_bis.a3m’\n",
      "‘infA_pf5_ortho_tris/infA_pf5_ortho_tris.a2m’ -> ‘infA_pf5_ortho_tris/infA_pf5_ortho_tris.a3m’\n",
      "‘aroB_pf5_ortho_tris/aroB_pf5_ortho_tris.a2m’ -> ‘aroB_pf5_ortho_tris/aroB_pf5_ortho_tris.a3m’\n"
     ]
    }
   ],
   "source": [
    "for protein in proteins:\n",
    "    protpath = Path(protein, protein)\n",
    "    !mv -uv {protpath.with_suffix('.a2m')} {protpath.with_suffix('.a3m')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check WT sequence names and seqs\n",
    "for protein in proteins:\n",
    "    !head -2 {Path(protein, protein).with_suffix('.a3m')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Input MSA has 653 sequences and 72 columns\n",
      "Convert infA_pf5_ortho/infA_pf5_ortho.a3m --> infA_pf5_ortho/infA_pf5_ortho.fasta OK!\n",
      "INFO: Input MSA has 620 sequences and 366 columns\n",
      "Convert aroB_pf5_ortho/aroB_pf5_ortho.a3m --> aroB_pf5_ortho/aroB_pf5_ortho.fasta OK!\n",
      "INFO: Input MSA has 3087 sequences and 72 columns\n",
      "Convert infA_pf5_ortho_bis/infA_pf5_ortho_bis.a3m --> infA_pf5_ortho_bis/infA_pf5_ortho_bis.fasta OK!\n",
      "INFO: Input MSA has 5492 sequences and 366 columns\n",
      "Convert aroB_pf5_ortho_bis/aroB_pf5_ortho_bis.a3m --> aroB_pf5_ortho_bis/aroB_pf5_ortho_bis.fasta OK!\n",
      "INFO: Input MSA has 5850 sequences and 72 columns\n",
      "Convert infA_pf5_ortho_tris/infA_pf5_ortho_tris.a3m --> infA_pf5_ortho_tris/infA_pf5_ortho_tris.fasta OK!\n",
      "INFO: Input MSA has 5554 sequences and 366 columns\n",
      "Convert aroB_pf5_ortho_tris/aroB_pf5_ortho_tris.a3m --> aroB_pf5_ortho_tris/aroB_pf5_ortho_tris.fasta OK!\n",
      "CPU times: user 5.05 s, sys: 19.2 ms, total: 5.07 s\n",
      "Wall time: 5.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for protein in proteins:\n",
    "    try:\n",
    "        reformat_msa(protein, srcfmt='a3m', tgtfmt='fasta')\n",
    "    except FileNotFoundError:\n",
    "        if Path(protein, protein).with_suffix('.fasta').exists():\n",
    "            print(f'WARNING! For {protein}, a3m file not found but fasta found!')\n",
    "        else:\n",
    "            print(f'ERROR! For {protein}, neither a3m or fasta file found!')\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMMBUILD = Path('/usr/workspace/kpath/cameos/hmmer/bin/hmmbuild')\n",
    "HMMPRESS = Path('/usr/workspace/kpath/cameos/hmmer/bin/hmmpress')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmmbuild(protein: str) -> None:\n",
    "    \"\"\"Wrapper for HMMER's hmmbuild\"\"\"\n",
    "    \n",
    "    protpath = Path(protein, protein)\n",
    "    !{str(HMMBUILD)} --cpu 16 {protpath.with_suffix('.hmm')} {protpath.with_suffix('.fasta')} >> {protpath.with_suffix('.hmmbld.out')}\n",
    "    if protpath.with_suffix('.hmm').exists():\n",
    "        print(f'OK! hmmbuild was successful for {protein}')\n",
    "    else:\n",
    "        print(f'ERROR! hmmbuild output missing for {protein}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmmpress(protein: str) -> None:\n",
    "    \"\"\"Wrapper for HMMER's hmmpress\"\"\"\n",
    "    \n",
    "    protpath = Path(protein, protein)\n",
    "    !{str(HMMPRESS)} -f {protpath.with_suffix('.hmm')} >> {protpath.with_suffix('.hmmpss.out')}\n",
    "    if protpath.with_suffix('.hmm.h3m').exists() and protpath.with_suffix('.hmm.h3p').exists():\n",
    "        print(f'OK! hmmpress was successful for {protein}')\n",
    "    else:\n",
    "        print(f'ERROR! hmmpress output missing for {protein}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM build and compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK! hmmbuild was successful for infA_pf5_ortho\n",
      "OK! hmmbuild was successful for aroB_pf5_ortho\n",
      "OK! hmmbuild was successful for infA_pf5_ortho_bis\n",
      "OK! hmmbuild was successful for aroB_pf5_ortho_bis\n",
      "OK! hmmbuild was successful for infA_pf5_ortho_tris\n",
      "OK! hmmbuild was successful for aroB_pf5_ortho_tris\n",
      "CPU times: user 33 ms, sys: 40.6 ms, total: 73.6 ms\n",
      "Wall time: 3.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for protein in proteins:\n",
    "    hmmbuild(protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK! hmmpress was successful for infA_pf5_ortho\n",
      "OK! hmmpress was successful for aroB_pf5_ortho\n",
      "OK! hmmpress was successful for infA_pf5_ortho_bis\n",
      "OK! hmmpress was successful for aroB_pf5_ortho_bis\n",
      "OK! hmmpress was successful for infA_pf5_ortho_tris\n",
      "OK! hmmpress was successful for aroB_pf5_ortho_tris\n"
     ]
    }
   ],
   "source": [
    "for protein in proteins:\n",
    "    hmmpress(protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‘infA_pf5_ortho/infA_pf5_ortho.hmm’ -> ‘../hmms/infA_pf5_ortho.hmm’\n",
      "‘aroB_pf5_ortho/aroB_pf5_ortho.hmm’ -> ‘../hmms/aroB_pf5_ortho.hmm’\n",
      "‘infA_pf5_ortho_bis/infA_pf5_ortho_bis.hmm’ -> ‘../hmms/infA_pf5_ortho_bis.hmm’\n",
      "‘aroB_pf5_ortho_bis/aroB_pf5_ortho_bis.hmm’ -> ‘../hmms/aroB_pf5_ortho_bis.hmm’\n",
      "‘infA_pf5_ortho_tris/infA_pf5_ortho_tris.hmm’ -> ‘../hmms/infA_pf5_ortho_tris.hmm’\n",
      "‘aroB_pf5_ortho_tris/aroB_pf5_ortho_tris.hmm’ -> ‘../hmms/aroB_pf5_ortho_tris.hmm’\n"
     ]
    }
   ],
   "source": [
    "for protein in proteins:\n",
    "    !cp {Path(protein, protein).with_suffix('.hmm.h??')} {Path('..', 'hmms')}\n",
    "    !cp -v {Path(protein, protein).with_suffix('.hmm')} {Path('..', 'hmms')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRF branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSA2CCM = BASE / Path('CCMpred/scripts/convert_alignment.py')\n",
    "CCMPRED = BASE /Path('CCMpred/bin/ccmpred')\n",
    "JULIA = Path('/usr/gapps/julia/bin/julia-1.6.3') #was before: /usr/workspace/kpath/julia/julia\n",
    "CCM2JLD = BASE / Path('CAMEOX/prepare/convert_ccm_to_jld.jl')\n",
    "ENGYPSLS = BASE / Path('CAMEOX/prepare/energies_and_psls.jl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msa2ccm(protein: str) -> None:\n",
    "    \"\"\"Wrapper for convert_alignment\"\"\"\n",
    "    \n",
    "    protpath = Path(protein, protein)\n",
    "    !{str(MSA2CCM)} {protpath.with_suffix('.fasta')} fasta {protpath.with_suffix('.ccm')}\n",
    "    if protpath.with_suffix('.ccm').exists():\n",
    "        print(f'OK! msa2ccm was successful for {protein}')\n",
    "    else:\n",
    "        print(f'ERROR! msa2ccm output missing for {protein}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccmpred(protein: str, numiter:int=100, threads:int=32) -> None:\n",
    "    \"\"\"Wrapper for CCMpred\"\"\"\n",
    "    \n",
    "    protpath = Path(protein, protein)\n",
    "    !{str(CCMPRED)} -r {protpath.with_suffix('.raw')} -n {numiter} -t {threads} {protpath.with_suffix('.ccm')} {protpath.with_suffix('.mat')} >> {protpath.with_suffix('.ccmprd.out')} \n",
    "    if protpath.with_suffix('.raw').exists():\n",
    "        print(f'OK! CCMpred was successful for {protein}')\n",
    "    else:\n",
    "        print(f'ERROR! CCMpred raw file missing for {protein}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccm2jld(protein: str) -> None:\n",
    "    \"\"\"Wrapper for convert_ccm_to_jld\"\"\"\n",
    "    \n",
    "    protpath = Path(protein, protein)\n",
    "    jld_path = Path('..', 'jlds', protein).with_suffix('.jld')\n",
    "    !{str(JULIA)} {str(CCM2JLD)} {protpath.with_suffix('.raw')} {jld_path}\n",
    "    if jld_path.exists():\n",
    "        print(f'OK! ccm2jld was successful for {protein}')\n",
    "    else:\n",
    "        print(f'ERROR! ccm2jld output missing for {protein}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engypsls(protein: str) -> None:\n",
    "    \"\"\"Wrapper for energy_and_psls\"\"\"\n",
    "    \n",
    "    print(f'\\n>>> Sumarizing energy and psls for {protein}...')\n",
    "    protpath = Path(protein, protein)\n",
    "    jld_path = Path('..', 'jlds', protein).with_suffix('.jld')\n",
    "    !{str(JULIA)} {str(ENGYPSLS)} {protein} {jld_path} {protpath.with_suffix('.fasta')}\n",
    "    engy_path = Path('energy_' + protein).with_suffix('.txt')\n",
    "    psls_path = Path('psls_' + protein).with_suffix('.txt')\n",
    "    if engy_path.exists() and psls_path.exists():\n",
    "        !mv -v {str(engy_path)} {str(Path('..', 'energies') / engy_path)}\n",
    "        !mv -v {str(psls_path)} {str(Path('..', 'psls') / psls_path)}        \n",
    "        print(f'OK! engypsls was successful for {protein}')\n",
    "    else:\n",
    "        print(f'ERROR! energy and/or psls output missing for {protein}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the custom MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK! msa2ccm was successful for infA_pf5_ortho\n",
      "OK! msa2ccm was successful for aroB_pf5_ortho\n",
      "OK! msa2ccm was successful for infA_pf5_ortho_bis\n",
      "OK! msa2ccm was successful for aroB_pf5_ortho_bis\n",
      "OK! msa2ccm was successful for infA_pf5_ortho_tris\n",
      "OK! msa2ccm was successful for aroB_pf5_ortho_tris\n",
      "CPU times: user 20.9 ms, sys: 52.3 ms, total: 73.2 ms\n",
      "Wall time: 1.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for protein in proteins:\n",
    "    msa2ccm(protein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training MRF —SLURM—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Interactive run of CCMpred in the local machine (not recommended)\n",
    "#for protein in proteins:\n",
    "#    ccmpred(protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Submitting CMMpred/CUDA job in pascal for infA_pf5_ortho...\n",
      "['Submitted batch job 1421666 on cluster pascal']\n",
      "> Submitting CMMpred/CUDA job in pascal for aroB_pf5_ortho...\n",
      "['Submitted batch job 1421667 on cluster pascal']\n",
      "> Submitting CMMpred/CUDA job in pascal for infA_pf5_ortho_bis...\n",
      "['Submitted batch job 1421668 on cluster pascal']\n",
      "> Submitting CMMpred/CUDA job in pascal for aroB_pf5_ortho_bis...\n",
      "['Submitted batch job 1421669 on cluster pascal']\n",
      "> Submitting CMMpred/CUDA job in pascal for infA_pf5_ortho_tris...\n",
      "['Submitted batch job 1421670 on cluster pascal']\n",
      "> Submitting CMMpred/CUDA job in pascal for aroB_pf5_ortho_tris...\n",
      "['Submitted batch job 1421671 on cluster pascal']\n"
     ]
    }
   ],
   "source": [
    "# Submit CCMpred with CUDA support to batch system in pascal (pvis queue limit 12h)\n",
    "for protein in proteins:\n",
    "    print(f'> Submitting CMMpred/CUDA job in pascal for {protein}...')    \n",
    "    sbatch_msg = !sbatch CCMpred-CUDA_jobscript.sh {protein}\n",
    "    print(sbatch_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER: pascal\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           1421671      pvis CCMpred-  metagen PD       0:00      1 (Priority)\n",
      "           1421670      pvis CCMpred-  metagen PD       0:00      1 (Priority)\n",
      "           1421669      pvis CCMpred-  metagen PD       0:00      1 (Priority)\n",
      "           1421668      pvis CCMpred-  metagen PD       0:00      1 (Priority)\n",
      "           1421667      pvis CCMpred-  metagen PD       0:00      1 (Priority)\n",
      "           1421666      pvis CCMpred-  metagen PD       0:00      1 (Priority)\n",
      ".....\n",
      " CLUSTER: pascal\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) \n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# Check the jobs are finished before proceeding further\n",
    "squeue_msg = !squeue -M pascal -u {USERNAME}\n",
    "done:bool = False\n",
    "print('\\n'.join(squeue_msg))\n",
    "while not done:\n",
    "    if any('CCMpred' in line for line in squeue_msg):\n",
    "        print('.', end='', flush=True)\n",
    "        time.sleep(20)\n",
    "        squeue_msg = !squeue -M pascal -u {USERNAME}\n",
    "    else:\n",
    "        done = True\n",
    "        print('\\n', '\\n'.join(squeue_msg), '\\nDONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the raw matrix to a JLD file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK! ccm2jld was successful for infA_pf5_ortho\n",
      "OK! ccm2jld was successful for aroB_pf5_ortho\n",
      "OK! ccm2jld was successful for infA_pf5_ortho_bis\n",
      "OK! ccm2jld was successful for aroB_pf5_ortho_bis\n",
      "OK! ccm2jld was successful for infA_pf5_ortho_tris\n",
      "OK! ccm2jld was successful for aroB_pf5_ortho_tris\n",
      "CPU times: user 695 ms, sys: 365 ms, total: 1.06 s\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for protein in proteins:\n",
    "    if Path(protein, protein).with_suffix('.raw').exists():\n",
    "        ccm2jld(protein)\n",
    "    else:\n",
    "        print(f'ERROR! Raw (input) file not present for protein {protein}!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize energies and psls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#for protein in proteins:\n",
    "#    engypsls(protein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SLURM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Submitting energy&psls job for infA_pf5_ortho...\n",
      "['Submitted batch job 86789 on cluster mammoth']\n",
      "> Submitting energy&psls job for aroB_pf5_ortho...\n",
      "['Submitted batch job 86790 on cluster mammoth']\n",
      "> Submitting energy&psls job for infA_pf5_ortho_bis...\n",
      "['Submitted batch job 86791 on cluster mammoth']\n",
      "> Submitting energy&psls job for aroB_pf5_ortho_bis...\n",
      "['Submitted batch job 86792 on cluster mammoth']\n",
      "> Submitting energy&psls job for infA_pf5_ortho_tris...\n",
      "['Submitted batch job 86793 on cluster mammoth']\n",
      "> Submitting energy&psls job for aroB_pf5_ortho_tris...\n",
      "['Submitted batch job 86794 on cluster mammoth']\n"
     ]
    }
   ],
   "source": [
    "for protein in proteins:\n",
    "    print(f'> Submitting energy&psls job for {protein}...')\n",
    "    sbatch_msg = !sbatch engypsls_jobscript.sh {protein}  # Uncomment this line for real submission\n",
    "    print(sbatch_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER: mammoth\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "             86794    pbatch engypsls  metagen PD       0:00      1 (Resources)\n",
      "             86793    pbatch engypsls  metagen PD       0:00      1 (Resources)\n",
      "             86792    pbatch engypsls  metagen PD       0:00      1 (Resources)\n",
      "             86791    pbatch engypsls  metagen PD       0:00      1 (Resources)\n",
      "             86790    pbatch engypsls  metagen PD       0:00      1 (Priority)\n",
      "             86789    pbatch engypsls  metagen PD       0:00      1 (Resources)\n",
      "..................................\n",
      " CLUSTER: mammoth\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON) \n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# Check the jobs are finished before proceeding further\n",
    "squeue_msg = !squeue -u {USERNAME}\n",
    "done:bool = False\n",
    "print('\\n'.join(squeue_msg))\n",
    "while not done:\n",
    "    if any('engypsls' in line for line in squeue_msg): \n",
    "        print('.', end='', flush=True)\n",
    "        time.sleep(20)\n",
    "        squeue_msg = !squeue -u {USERNAME}\n",
    "    else:\n",
    "        done = True\n",
    "        print('\\n', '\\n'.join(squeue_msg), '\\nDONE!')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Copying energy and psls files for infA_pf5_ortho...\n",
      "‘infA_pf5_ortho/energy_infA_pf5_ortho.txt’ -> ‘../energies/energy_infA_pf5_ortho.txt’\n",
      "‘infA_pf5_ortho/psls_infA_pf5_ortho.txt’ -> ‘../psls/psls_infA_pf5_ortho.txt’\n",
      "\n",
      ">>> Copying energy and psls files for aroB_pf5_ortho...\n",
      "‘aroB_pf5_ortho/energy_aroB_pf5_ortho.txt’ -> ‘../energies/energy_aroB_pf5_ortho.txt’\n",
      "‘aroB_pf5_ortho/psls_aroB_pf5_ortho.txt’ -> ‘../psls/psls_aroB_pf5_ortho.txt’\n",
      "\n",
      ">>> Copying energy and psls files for infA_pf5_ortho_bis...\n",
      "‘infA_pf5_ortho_bis/energy_infA_pf5_ortho_bis.txt’ -> ‘../energies/energy_infA_pf5_ortho_bis.txt’\n",
      "‘infA_pf5_ortho_bis/psls_infA_pf5_ortho_bis.txt’ -> ‘../psls/psls_infA_pf5_ortho_bis.txt’\n",
      "\n",
      ">>> Copying energy and psls files for aroB_pf5_ortho_bis...\n",
      "‘aroB_pf5_ortho_bis/energy_aroB_pf5_ortho_bis.txt’ -> ‘../energies/energy_aroB_pf5_ortho_bis.txt’\n",
      "‘aroB_pf5_ortho_bis/psls_aroB_pf5_ortho_bis.txt’ -> ‘../psls/psls_aroB_pf5_ortho_bis.txt’\n",
      "\n",
      ">>> Copying energy and psls files for infA_pf5_ortho_tris...\n",
      "‘infA_pf5_ortho_tris/energy_infA_pf5_ortho_tris.txt’ -> ‘../energies/energy_infA_pf5_ortho_tris.txt’\n",
      "‘infA_pf5_ortho_tris/psls_infA_pf5_ortho_tris.txt’ -> ‘../psls/psls_infA_pf5_ortho_tris.txt’\n",
      "\n",
      ">>> Copying energy and psls files for aroB_pf5_ortho_tris...\n",
      "‘aroB_pf5_ortho_tris/energy_aroB_pf5_ortho_tris.txt’ -> ‘../energies/energy_aroB_pf5_ortho_tris.txt’\n",
      "‘aroB_pf5_ortho_tris/psls_aroB_pf5_ortho_tris.txt’ -> ‘../psls/psls_aroB_pf5_ortho_tris.txt’\n"
     ]
    }
   ],
   "source": [
    "for protein in proteins:\n",
    "    print(f'\\n>>> Copying energy and psls files for {protein}...')\n",
    "    engy_path = Path(protein, 'energy_' + protein).with_suffix('.txt')\n",
    "    psls_path = Path(protein, 'psls_' + protein).with_suffix('.txt')\n",
    "    if engy_path.exists() and psls_path.exists():\n",
    "        !cp -v {str(engy_path)} {str(Path('..', 'energies'))}\n",
    "        !cp -v {str(psls_path)} {str(Path('..', 'psls'))}        \n",
    "    else:\n",
    "        print(f'ERROR! energy and/or psls output missing for {protein}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 for CAMEOX",
   "language": "python",
   "name": "cameox_py3.8.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
